{
  "hash": "50b27ab4e65c5a1bdf320cbaf9193f25",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"SOD assay for nickel LC50 samples\"\nauthor: \"Celeste Valdivia\"\ndate: \"2024-07-06\"\n---\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(knitr)\nlibrary(tidyverse)\nlibrary(tidyr)\nlibrary(dplyr)\nlibrary(hrbrthemes)\nlibrary(ggplot2)\nlibrary(car)\nlibrary(RColorBrewer)\nlibrary(ggpubr)\nknitr::opts_chunk$set(echo = TRUE,\n                      eval = TRUE)\n```\n:::\n\n# Background\nAn LC50 determination for nickel on *Botryllus schlosseri* was completed in Spring Quarter 2024. Specimens were snap frozen at the 24 and 96 hour mark to assess for accumulation of Superoxide Dismutase 1 (SOD1). SOD1 is an endogenous antioxidant with a primary function involving the removal of reactive oxygen species (ROS). \n\nNickel genotoxicity functions indirectly through the resultant intracellular accumulation of ROS in most animal cells. ROS cause double and single stranded breaks to the DNA which inevitably may result in mutations forming at the cellular attempts to repair the DNA.\n\nHere we explore the effects of increasing concentrations of nickel on the accumulation of SOD1 in *B. schlosseri*.\n\n\n# Retrieving Data from Google Sheets\n\n## SOD Data\n\nMake sure you have made your Google sheet publicly available to anyone that has the link. If you make any updates to the sheet just re-curl the data, meaning just re-run the code below.\n\nI apologize for not making a relative path. Just modify what is after \"tee\" to your own directory path.\n\n\n::: {.cell}\n\n```{.bash .cell-code}\ncurl -L https://docs.google.com/spreadsheets/d/1vNxX2tBdEa0Ibyd4mFdru5sAZx0aipv37-y-hkqvJq4/export?exportFormat=csv | tee /Users/valeste/Documents/Git/tough-tunicates/posts/LC50-SOD/SOD.csv\n```\n:::\n\n## BCA Data\n\n\n::: {.cell}\n\n```{.bash .cell-code}\n\ncurl -L https://docs.google.com/spreadsheets/d/1mKhd95gn_tith8fJbYjX3jGyrO-Y4mWKCoCKdTVZFHY/export?exportFormat=csv | tee /Users/valeste/Documents/Git/tough-tunicates/posts/LC50-SOD/BCA.csv\n\n```\n:::\n\n\n### Read in the data to your global environment\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsod <- read.csv(\"SOD.csv\")\n\n#let's take a peak\nhead(sod)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  well_content tech_rep hom_num date_assay treatment hpe sod_calc\n1 Hom 1 1:3 R1       R1       1     7/2/24         0  24 2.305306\n2 Hom 1 1:3 R2       R2       1     7/2/24         0  24 2.179302\n3 Hom 2 1:3 R1       R1       2     7/2/24         0  24 4.959112\n4 Hom 2 1:3 R2       R2       2     7/2/24         0  24 3.800808\n5 Hom 3 1:3 R1       R1       3     7/2/24         0  24 3.495769\n6 Hom 3 1:3 R2       R2       3     7/2/24         0  24 1.962912\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nbca <- read.csv(\"BCA.csv\")\n\n#another little peak\nhead(bca)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  protein_conc.mg.mL well_content hom_num tech_rep well plate assay_date\n1          0.2905277 Hom 1 1:4 R1       1       R1   A1     2     7/4/24\n2          0.2385391 Hom 1 1:4 R2       1       R2   B1     2     7/4/24\n3          0.2388732 Hom 1 1:4 R3       1       R3   C1     2     7/4/24\n4          0.3881566 Hom 2 1:4 R1       2       R1   A2     2     7/4/24\n5          0.3379439 Hom 2 1:4 R2       2       R2   B2     2     7/4/24\n6          0.3473041 Hom 2 1:4 R3       2       R3   C2     2     7/4/24\n  treatment\n1         0\n2         0\n3         0\n4         0\n5         0\n6         0\n```\n\n\n:::\n:::\n\n\nIn the BCA data frame, we are missing the hpe associated with the each sample. We can add this on to a new data frame that also combines it with the SOD data after we take the averages and standard errors of the technical replicates of the BCA assay.\n\n::: {.callout-note}\nNote that as of July 3, 2024, the data set for the 10 mg/L is incomplete in this data frame and should be taken with a grain of salt or removed from the data frame below. The 0 mg/L treatment is also incomplete with homogenate 37 needing to be re-evaluated.\n:::\n\n# Data Munging!\n\n## Filter Data\n\nClean up SOD data\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_clean_sod <- sod %>%\n  filter(!is.na(sod_calc)) %>% # remove any rows with NA\n  filter(treatment != 10) # remove the 10 mg/L treatment since the reps have not all been processed yet\n```\n:::\n\n\nClean up BCA data\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_clean_bca <- bca %>%\n  filter(!is.na(protein_conc.mg.mL)) %>% # remove any rows with NA\n  filter(treatment != 10) # remove the 10 mg/L treatment since the reps have not all been processed yet\n```\n:::\n\n\n## Average assays' technical replicates\n\nGet the mean and standard error of the technical replicates for SOD:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_avg_sod <- df_clean_sod %>%\n  group_by(hom_num, treatment, hpe) %>%\n  summarize(\n    sod_avg = mean(sod_calc, na.rm = TRUE),\n    sod_se = sd(sod_calc, na.rm = TRUE) / sqrt(n())\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'hom_num', 'treatment'. You can override\nusing the `.groups` argument.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ndf_avg_bca <- df_clean_bca %>%\n  group_by(hom_num, treatment) %>%\n  summarize(\n    bca_avg = mean(protein_conc.mg.mL, na.rm = TRUE),\n    bca_se = sd(protein_conc.mg.mL, na.rm = TRUE) / sqrt(n())\n  )\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\n`summarise()` has grouped output by 'hom_num'. You can override using the\n`.groups` argument.\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ncombo <- inner_join(df_avg_sod, df_avg_bca, by = c(\"hom_num\", \"treatment\"))\nhead(combo)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 6 Ã— 7\n# Groups:   hom_num, treatment [6]\n  hom_num treatment   hpe sod_avg sod_se bca_avg  bca_se\n    <int>     <int> <int>   <dbl>  <dbl>   <dbl>   <dbl>\n1       1         0    24   2.24  0.0630   0.256 0.0173 \n2       2         0    24   4.38  0.579    0.358 0.0154 \n3       3         0    24   2.73  0.766    0.357 0.00688\n4       7         1    24   8.36  0.513    0.542 0.0430 \n5       8         1    24   0.487 0.100    0.483 0.0125 \n6       9         1    24   2.81  1.05     0.345 0.0184 \n```\n\n\n:::\n:::\n\n\n::: {.callout-note}\nThe column sod_avg is in activity units/mL and the column bca_avg is in mg/mL.\n:::\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncombo <- combo %>%\n  mutate(sod_u_mg = sod_avg / bca_avg)\n```\n:::\n\n\n\n# Exploratory Plots\n\nNote that the plot below is the unormalized data. A BCA was run on the samples as well to quantify total protein content.\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(combo, aes(x = factor(treatment), y = sod_avg, fill = factor(treatment))) +\n  geom_violin(trim = FALSE) +\n  facet_wrap(~ hpe, scales = \"free_y\") +\n  labs(title = \"Violin Plot of SOD Activity (u/mL) by Treatment and HPE\",\n       fill = \"Nickel Concentration\",\n       x = \"Treatment\",\n       y = \"SOD Activity\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\nSOD1 activity normalized to the protein content per sample:\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(combo, aes(x = factor(treatment), y = sod_u_mg, fill = factor(treatment))) +\n  geom_violin(trim = FALSE) +\n  facet_wrap(~ hpe, scales = \"free_y\") +\n  labs(title = \"Violin Plot of SOD Activity (u/mg) by Treatment and HPE\",\n       fill = \"Nickel Concentration\",\n       x = \"Treatment\",\n       y = \"SOD Activity\") \n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\n\n# Statistical Analysis\n\nWe will run a two-way ANOVA on the data exploring sod1 activity units/mg of protein by hours post exposure and nickel concentration.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Perform ANOVA\nanova_result <- aov(sod_u_mg ~ hpe * treatment, data = combo)\n\n# Summarize ANOVA results\nsummary(anova_result)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n              Df Sum Sq Mean Sq F value Pr(>F)\nhpe            1      2    1.58   0.017  0.897\ntreatment      1     96   95.96   1.037  0.315\nhpe:treatment  1     42   42.47   0.459  0.502\nResiduals     41   3795   92.56               \n```\n\n\n:::\n:::\n\n## ANOVA Conclusions\n\nSOD1 activity does not differ across nickel concentration treatment groups or even the control at either the 24 or 96 hours post exposure mark.\n\n# Next Steps?\n\nThere could be various reasons why we did not observe the expected effect of increased SOD activity with increasing concentrations of nickel.\n\n## Power Analysis\nCurrently this will only work below if the groups are of equal sample size. Because I have yet to re-process the homogenate 37 (the final replicate for the control) this analysis cannot work.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(pwr)\nanova_result <- aov(sod_u_mg ~ hpe * treatment, data = combo)\nsummary_result <- summary(anova_result)\n\n# Extract the sum of squares\nss_total <- sum(summary_result[[1]][, \"Sum Sq\"])\nss_residual <- summary_result[[1]][\"Residuals\", \"Sum Sq\"]\n\n# Calculate eta squared\neta_squared <- 1 - (ss_residual / ss_total)\n\n# Calculate effect size f\neffect_size_f <- sqrt(eta_squared / (1 - eta_squared))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\n# Number of groups in your ANOVA (e.g., hpe * treatment)\nnum_groups <- length(unique(combo$hpe)) * length(unique(combo$treatment))\n\n# Significance level (commonly set to 0.05)\nalpha <- 0.05\n\n# Sample size (total number of observations)\nsample_size <- nrow(combo)\n\n# Conduct power analysis\npower_analysis <- pwr.anova.test(k = num_groups, f = effect_size_f, sig.level = alpha, n = sample_size / num_groups)\n\n# Print the result\nprint(power_analysis)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n     Balanced one-way analysis of variance power calculation \n\n              k = 6\n              n = 7.5\n              f = 0.1920704\n      sig.level = 0.05\n          power = 0.1238005\n\nNOTE: n is number in each group\n```\n\n\n:::\n:::\n\nNote that n = 7.5 is in relation to the unequal sample sizes per group which is in relation to the missing control sample, homogenate 37.\n\nPower (0.1238005): The power of 0.1238 indicates that this study has a low probability (approximately 12.38%) of detecting the true effect (f = 0.1920704) under the current conditions (sample sizes, effect size, and significance level).\n\nConsiderations: To increase power, we may need to consider increasing the sample size per group, using more sensitive measures, or adjusting your study design to reduce variability.",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}